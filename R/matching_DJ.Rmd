---
title: "Group 1: Matching"
author: "Ashrita Achar, Daniel Jost, Aurélien Leyder & Lea Rodiqi"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: rmdformats::robobook
---

```{r setup, include=FALSE}
# using package rmdformats for html output

knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(class.source="bg-warning")

knitr::opts_knit$set(root.dir = "~/GitHub/ecls") # change working directory
```

```{=html} 
<!-- COMMENTS (not included in html)

Task assignment
· Every working group prepares a tutorial in the format of a lecturecast. Could also be several smaller lecturecasts but the total running time should be at least 30 minutes (not significantly less). Free software: e.g. movavi, camstudio, VLC player, etc.

· I leave it up to you how you divide the work within your group (i.e. if 1 person speaks all the time, or if you divide it etc. 1 file vs multiple lecturecast files). The lecture cast should contain instructions you would have given anyway in class. Everything else is up to you. 

· Note that the focus of the lecturecasts is on application in statistical software and on interpretation of results. You don't have the explain the method itself again in great detail.

Please upload  small document that contains a) the link to the lecturecast b) some additional exercises for the hands-on tutorial. You find your group deadline on learn@wu.

Please also e-mail me (stefan.angel@wu.ac.at) a document that c) illustrates the solutions to these exercises. Same deadline as above.

Both b) and c) can be in any format you like (e.g. again lecture casts with instructions and solutions or a simple pdf with information in writing).

extension ideas (can also be used as exercises):
- illustrate curse of dimensionality aka why exact matching might not be a good idea
- use different matching algo than NN
- include more/other covariates*
- use other estimation method (e.g. combine with did)
- use different data

* Variables that influence simultaneously the treatment likelihood and the outcome AND
* Variables that cannot be influenced by the treatment (slide 34, see also slide 35)

common support (slide 39): Minima and maxima comparison & Trimming


additional exercises for the hands-on tutorial (as PDF):
- interpret at the end
- which matching method worked the best?
- change

-->
```

`5765 - Specialization: Economic and Social Policy`

# Introduction

This tutorial is based on a [Matching-Tutorial by Simon Ejdemyr](https://github.com/sejdemyr/ecls) using [US data](https://www.childandfamilydataarchive.org/cfda/archives/cfda/studies/4075) on student achievements (math test scores) and school types (public and catholic) for young pupils from the turn of the millennium. More specifically we are interested the effect of going to a Catholic school, as opposed to a public school, on student achievement. As we will see in the pre-analysis, students from Catholic schools are on average different from students who attend public school. Thus, they are not directly comparable and assuming selection on observable we perform matching to generate a sample in which treatment (in our case going to a catholic school) is independent of covariates.

**Code Sources:** [Tutorial by Ejdemyr](https://github.com/sejdemyr/ecls), [MatchIt](https://cran.r-project.org/web/packages/MatchIt)

**Data Source:** [childandfamilydataarchive.org](https://www.childandfamilydataarchive.org/cfda/archives/cfda/studies/4075)

First, there are some steps that the R code works on your computer. Second, we will briefly repeat the main intuition and options when using matching methods. Third, some data wrangling is necessary to prepare the data and after that we will, finally, start with the actual tutorial which is structured as follows:

1. Pre-analysis
   
2. Propensity score estimation
   
3. Region of common support

4. Matching Magic

5. Checking balance

6. Estimating treatment effects

## Setup

For the R code (as an Rmd file) to work you need to 

(1) Download the data 

(2) Change the working directory

(3) Install required packages


### (1) Download the data

- Go to [https://www.childandfamilydataarchive.org/cfda/archives/cfda/studies/4075](https://www.childandfamilydataarchive.org/cfda/archives/cfda/studies/4075)

- Click on 'Download', choose 'SPSS', read and accept the Terms of Use

- Annoying but necessary: create an account (using Google, LinkedIn or from scratch)

- Then you should be prompted to a page that automatically downloads the ZIP-file (57 MB)

- Unzip the downloaded zip file. In it, there's a file called '04075-0001-Data.por'. Place this file directly in your working directory of R


### (2) Change the working directory

Change the working directory in the setup chunk of the Rmd file `knitr::opts_knit$set(root.dir = "insert/working/directory")`


### (3) Install required packages
install required packages if there not installed yet using `install.packages()` and load them in your current library
```{r, message=FALSE}
library(tidyverse)   # welcome to the dark side
library(haven)       # to import spss files
library(sjmisc)      # data and variable transformation
library(MatchIt)     # matching fun
```

For R there are two main packages for matching: 

- `MatchIt`, which will be used in this tutorial and 

- `Matching`

## Matching

### General intuition of matching

1. for each treated observation, ﬁnd a non-treated observation that is as similar as possible

2. compare outcomes between treated and non-treated groups

> "The goal of matching is to produce covariate balance, that is, for the distributions of covariates in the two groups to be approximately equal to each other, as they would be in a successful randomized experiment." ([MatchIt Vignette](https://cran.r-project.org/web/packages/MatchIt/vignettes/MatchIt.html))

### Options when using matching methods

- *Choice of covariates:* Variables that influence the treatment likelihood (propensity score) and the outcome AND that cannot be influenced by the treatment

- *Similarity measure:* coveriate vector (multi-dimensional) OR single index based on coveriates (one-dimensional, e.g. prpensity score)

- *Methods for choosing control observations (Number of matches per treated unit):* Nearest-neighbour (1:1 matching), M-nearest-neighbour (1:M matching), Kernel (1:all matching)

- *Distance measure:* e.g. Euclidean distance, Mahalanobis (covariance-normalized) distance ect.

- *Replacement*: with OR w/o replacement

- *Causal estimation method:* simple comparison of means, OLS, DiD etc.

\Rightarrow Since there are many subjective choices in matching setup reporting different matching methods is a good idea to reduce researcher bias.

# Data Wrangling

from ecls-clean.R of [Tutorial by Ejdemyr](https://github.com/sejdemyr/ecls)

-   An R script for processing data from the Early Childhood Longitudinal Study.

-   The output is saved to 'data-processed/ecls.csv'.

## Read data

Note: this may take a little while. If you're getting a "can't allocate memory" error, install the latest version of `haven` and restart R.

```{r}
dta <- read_por('data-raw/04075-0001-Data.por')
names(dta) <- tolower(names(dta))
```

## Convert variables

Convert variables of interest to character/numeric

```{r, warning=FALSE}
vars_chrs <- c("childid",
               "l5cathol",
               "l5public",
               "r5race",
               "w3povrty",
               "w3daded",
               "w3momed",
               "w3inccat",
               "p5fstamp")

vars_nums <- c("w3momscr",
               "w3dadscr",
               "p5numpla",
               "p5hmage",
               "p5hdage",
               "c5r2mtsc")

dta <- dta %>%
  mutate_at(vars(one_of(vars_chrs)), funs(as.character(to_label(.)))) %>%
  mutate_at(vars(one_of(vars_nums)), funs(as.numeric(as.character(to_label(.)))))
```

Select variables of interest

```{r}
dta <- dta %>% dplyr::select(one_of(c(vars_chrs, vars_nums)))
```

## Create dummies & recoding

Create catholic dummy: Filter down to catholic and public school students and create a dummy for catholic

```{r}
dta <- dta %>%
  filter(l5cathol == 'YES' | l5public == 'YES') %>%
  mutate(catholic = if_else(l5cathol == 'YES', 1, 0))
```

Create race dummies

```{r}
dta <- dta %>%
  mutate(race_white = if_else(r5race == 'WHITE, NON-HISPANIC', 1, 0),
         race_black = if_else(r5race == 'BLACK OR AFRICAN AMERICAN, NON-HISPANIC', 1, 0),
         race_hispanic = if_else(r5race %in% c('HISPANIC, RACE SPECIFIED', 'HISPANIC, RACE NOT SPECIFIED'), 1, 0),
         race_asian = if_else(r5race == 'ASIAN', 1, 0))
```

Set scores of 0 or below on occupational prestige scores, number of places lived, and mother's/father's age to NA

```{r}
dta <- dta %>%
  mutate_at(vars(w3momscr, w3dadscr, p5numpla, p5hmage, p5hdage),
            funs(ifelse(. <= 0, NA, .)))
```

Create poverty and food stamp dummies

```{r}
dta <- dta %>%
  mutate(w3povrty = if_else(w3povrty == 'BELOW POVERTY THRESHOLD', 1, 0),
         p5fstamp = if_else(p5fstamp == 'YES', 1, if_else(p5fstamp == 'NO', 0, as.double(NA))))
```

Create dummies for high school or below (grouping 'some college' as above)

```{r}
hs_cats <- c('8TH GRADE OR BELOW', '9TH - 12TH GRADE', 'HIGH SCHOOL DIPLOMA/EQUIVALENT',
             'VOC/TECH PROGRAM')
dta <- dta %>%
  mutate_at(vars(w3daded, w3momed),
            funs('hsb' = if_else(. %in% hs_cats, 1,
                          if_else(. == 'NOT APPLICABLE', as.double(NA), 0))))
```

Recode income categories to numeric: Income categories are set at their midvalue. 5000 or less is set to 5000; 200,001 or more is set to 200,001.

```{r}
dta <- dta %>%
  mutate(w3inccat = if_else(w3inccat == '$5,000 OR LESS', '$5,000 TO $5,000',
                            if_else(w3inccat == '$200,001 OR MORE', '$200,001 TO $200,001', w3inccat)))

convert_income <- function(s) {                              # function for converting income
  split_mat <- str_split_fixed(s, " TO ", n = 2)
  split_mat <- gsub('\\$|,', '', split_mat)
  (as.numeric(split_mat[, 1]) + as.numeric(split_mat[, 2])) / 2
}

test <- unique(dta$w3inccat)                                 # test function
data.frame(test, convert_income(test))

dta <- dta %>% mutate(w3income = convert_income(w3inccat))   # finally, convert income

```

## Standardized math score

Clean math t score and create a standardized score

```{r}
dta <- dta %>%
  mutate(c5r2mtsc = if_else(c5r2mtsc <= 0, as.double(NA), as.numeric(c5r2mtsc)),
         c5r2mtsc_std = (c5r2mtsc - mean(c5r2mtsc, na.rm = T)) / sd(c5r2mtsc, na.rm = T))
```

Remove observations with missing math score

```{r}
dta <- dta %>% filter(!c5r2mtsc %in% NA)
```

## Select and rename variables

```{r}
dta <- dta %>% dplyr::select(childid, catholic, race = r5race, race_white, race_black, race_hispanic, race_asian, p5numpla, p5hmage, p5hdage, w3daded, w3momed, w3daded_hsb, w3momed_hsb, w3momscr, w3dadscr, w3inccat, w3income, w3povrty, p5fstamp, test = c5r2mtsc, test_std = c5r2mtsc_std)

write.csv(dta, 'data-processed/ecls.csv', row.names = FALSE)
```

## Next Steps

1.  Pre-analysis

2.  Estimate propensity score

3.  Check and define region of common support (overlap)

4.  **Match**

5.  Examine covariate balance

6.  Estimate treatment effects

# 1. Pre-analysis
Pre-analysis using non-matched data

```{r}
setwd("~/GitHub/ecls/data-processed")
ecls <- read.csv("ecls.csv")

ecls <- ecls %>% mutate(w3income_1k = w3income / 1000)                    # ????
```

## Difference-in-means: outcome variable

Let's check the outcome difference on the raw data. The outcome variable is a math test score (standardized so that mean is 0 and standard deviation is one). The explanatory variable is a dummy indicating whether a student went to a catholic (catholic = 1) or public school (catholic = 0).

```{r, message=FALSE, warning=FALSE}
ecls %>%
  group_by(catholic) %>%
  summarise(n_students = n(),
            mean_test = mean(test_std),
            std_error = sd(test_std) / sqrt(n_students))
```

The average test score of students of catholic schools is more than 20% of a standard deviation higher than that of public school students. The small standard error indicates that this difference is statistically significant. To make sure let's perform a t-test.

```{r, message=FALSE, warning=FALSE}
with(ecls, t.test(test_std ~ catholic))
```
As expected the difference is highly significant.

## Difference-in-means: pre-treatment covariates

The following variables are used:

| name        | description   | class   | values |
|-------------|---------------|---------|--------|
| race_white  | Race          | dummy   | white (1) |
| w3income    | Family income | numeric | in steps of 2.500 |
| p5hmage     | Mother’s age  | numeric | |
| p5numpla    | Number of places the student has lived for at least 4 months | numeric | |
| w3momed_hsb | mother’s education level | dummy | high-school or below (1), college or more (0) |

Let’s calculate the mean for each covariate by the treatment status (catholic):

```{r, message=FALSE}
ecls_cov <- c('race_white', 'p5hmage', 'w3income', 'p5numpla', 'w3momed_hsb')

ecls %>%
  group_by(catholic) %>%
  select(one_of(ecls_cov)) %>%
  summarise_all(funs(mean(., na.rm = T)))
```

The most distinct differences are probably the higher percentage of white students, family income and  mother's education level for students of catholic schools. All of these differences are an indicator that the students are not directly comparable since the mother's education for example might be correlated with both the probability of treatment (going to a catholic school) and the student achievement (math test score).

Let's check if the differences are all significant.

```{r}
ttest <- lapply(ecls_cov, function(v) {
  t.test(ecls[, v] ~ ecls[, 'catholic'])
})

for (i in c(1:5)) {
  print(ttest[[i]]$p.value)
}
```
All differences are statistically significant.

## Formula

```{r}
formula <- catholic ~ race_white + w3income + p5hmage + p5numpla + w3momed_hsb
```

## Check Initial Imbalance
```{r}
ecls_nomiss <- ecls %>%  # MatchIt does not allow missing values
  select(test_std, catholic, one_of(ecls_cov)) %>%
  na.omit()
```

No matching yet but just constructing a pre-match matchit object to check balance prior to matching by setting `method = NULL`. With `distance` you set the method to estimate the propensity score. "glm" stands for "generalized linear model", which implements a logistic regression. Other options include "mahalanobis", "randomforest" etc. (call `?distance` for all options).
```{r}
pre_match <- matchit(formula, method = NULL, distance = "glm", data = ecls_nomiss)
dta_pre <- match.data(pre_match)
dim(dta_pre)
```
`dta_pre` will be used later to compare initial imbalance to the matched data.

# 2. Propensity score estimation



- Propensity score is the probability of treatment given the covariates (one-dimensional summary)

- outcome variable is a binary variable indicating treatment status

- we use a logit model (probit can also be used)

- any covariate that is related to both the treatment assignment and potential outcomes should be included

```{r}
m_ps <- glm(formula, family = binomial(), data = ecls)
summary(m_ps)
```

`predict()` calculates the propensity score which we save in a data frame
```{r}
prs_df <- data.frame(pr_score = predict(m_ps, type = "response"),
                     catholic = m_ps$model$catholic)
```

# 3. Region of common support

Next, we will check and define region of common support, that is the overlapping distribution of the propensity scores of students attending a catholic on the one hand and a public school on the other hand.

```{r, include=FALSE}
labs <- paste("Actual school type attended:", c("Catholic", "Public"))

prs_df %>%
  mutate(catholic = ifelse(catholic == 1, labs[1], labs[2])) %>%
  ggplot(aes(x = pr_score)) +
  geom_histogram(color = "white") +
  facet_wrap(~catholic) +
  xlab("Probability of going to Catholic school") +
  theme_bw()

ggplot(prs_df, aes(x = pr_score)) +
  geom_histogram(data=subset(prs_df, catholic == 0), fill="blue", color="white", alpha = .5) +
  geom_histogram(data=subset(prs_df, catholic == 1), fill="red",  color="white", alpha = .5) +
  xlab("Probability of going to Catholic school") +
  theme_bw()
```

```{r, message=FALSE, warning=FALSE}
ggplot(prs_df, aes(x = pr_score, fill = factor(catholic))) +
  geom_histogram(binwidth=.01, color = "#FFFFFFAA", alpha = 0.6) +
  xlab("Probability of going to Catholic school") +
  scale_y_continuous(expand = expansion(mult=c(0,0))) +
  scale_x_continuous(expand = expansion(mult=c(0,0))) +
  scale_fill_manual(name = "", values = c("red", "blue"), labels = c("Public", "Catholic")) +
  theme_bw() +
  theme(panel.border = element_blank())
```
```{r}
prs_df %>% group_by(catholic) %>% summarize(range(pr_score))
```
As we can see in the plot and from the summary table both students from catholic and public schools have a similar range of propensity scores. 

# 4. Matching Magic

Executing a matching algorithm

## Exact matching

pro: no functional form assumptions are required on either the treatment or outcome model

con: typically many units will be discarded (curse of dimensionality)

```{r}
x_match <- matchit(formula, method = "exact", data = ecls_nomiss,
                   estimand = "ATE", # controls how the weights are computed
                   k2k = TRUE,       
                   k2k.method = "mahalanobis")  # how the distance between units should be calculated if k2k = TRUE, "mahalanobis" for Mahalanobis distance matching
dta_x <- match.data(x_match)
dim(dta_x)
```

## Coarsened exact matching

```{r}
c_match <- matchit(formula, method = "cem", data = ecls_nomiss,
                   estimand = "ATE", # controls how the weights are computed
                   k2k = TRUE,       # if TRUE nearest neighbor matching without replacement will take place within each stratum, and any unmatched units will be dropped
                   k2k.method = "mahalanobis")  # how the distance between units should be calculated if k2k = TRUE, "mahalanobis" for Mahalanobis distance matching
dta_c <- match.data(x_match)
dim(dta_c)
```

## Nearest neighbor propensity score matching

```{r}
mod_match <- matchit(formula, method = "nearest", data = ecls_nomiss)
dta_m <- match.data(mod_match)
dim(dta_m)
```

# 5. Checking balance

## Visually

Ggplot function for visual comparison:
```{r}
fn_bal <- function(dta, variable) {
  dta$variable <- dta[, variable]
  dta$catholic <- as.factor(dta$catholic)
  ggplot(dta, aes(x = distance, y = variable, color = catholic)) +
    geom_point(alpha = 0.1, size = 1.5) +
    geom_smooth(method = "loess", se = F) +
    xlab("Propensity score") +
    ylab(variable) +
    scale_color_manual(name = "", values = c("red", "blue"), labels = c("Public", "Catholic")) +
    theme_bw() +
    theme(panel.border = element_blank())
}
```

### Before Matching
```{r, error=TRUE, message=FALSE}
library(gridExtra)
grid.arrange(
   fn_bal(dta_pre, "w3income"),
   fn_bal(dta_pre, "p5numpla") + theme(legend.position = "none"),
   fn_bal(dta_pre, "p5hmage"),
   fn_bal(dta_pre, "w3momed_hsb") + theme(legend.position = "none"),
   fn_bal(dta_pre, "race_white"),
   nrow = 3, widths = c(1, 0.85)
)
```

### Exact Matching
```{r, error=TRUE, message=FALSE}
library(gridExtra)
grid.arrange(
   fn_bal(dta_x, "w3income"),
   fn_bal(dta_x, "p5numpla") + theme(legend.position = "none"),
   fn_bal(dta_x, "p5hmage"),
   fn_bal(dta_x, "w3momed_hsb") + theme(legend.position = "none"),
   fn_bal(dta_x, "race_white"),
   nrow = 3, widths = c(1, 0.85)
)

```

### Coarsened Exact Matching
```{r, error=TRUE, message=FALSE}
library(gridExtra)
grid.arrange(
   fn_bal(dta_c, "w3income"),
   fn_bal(dta_c, "p5numpla") + theme(legend.position = "none"),
   fn_bal(dta_c, "p5hmage"),
   fn_bal(dta_c, "w3momed_hsb") + theme(legend.position = "none"),
   fn_bal(dta_c, "race_white"),
   nrow = 3, widths = c(1, 0.85)
)
```

### Neigherest neighbor propensity score matching
```{r, error=TRUE, message=FALSE}
library(gridExtra)
grid.arrange(
   fn_bal(dta_m, "w3income"),
   fn_bal(dta_m, "p5numpla") + theme(legend.position = "none"),
   fn_bal(dta_m, "p5hmage"),
   fn_bal(dta_m, "w3momed_hsb") + theme(legend.position = "none"),
   fn_bal(dta_m, "race_white"),
   nrow = 3, widths = c(1, 0.85)
)

```

## Mean difference

### Before Matching
```{r, error=TRUE, message=FALSE}
dta_pre %>%
    group_by(catholic) %>%
    summarise_all(funs(mean))
```

### Exact Matching
```{r, error=TRUE, message=FALSE}
dta_x %>%
    group_by(catholic) %>%
    summarise_all(funs(mean))
```

### Coarsened Exact Matching
```{r, error=TRUE, message=FALSE}
dta_c %>%
    group_by(catholic) %>%
    summarise_all(funs(mean))
```

### Neigherest neighbor propensity score matching
```{r, error=TRUE, message=FALSE}
dta_m %>%
    group_by(catholic) %>%
    summarise_all(funs(mean))
```

## T-test

### Before Matching
```{r, error=TRUE, message=FALSE}
ttest_pre <- lapply(ecls_cov, function(v) {
    t.test(dta_pre[, v] ~ dta_pre$catholic)
})

for (i in c(1:5)) {
  print(ttest_pre[[i]]$p.value)
}
```

### Exact Matching
```{r, error=TRUE, message=FALSE}
ttest_x <- lapply(ecls_cov, function(v) {
    t.test(dta_x[, v] ~ dta_x$catholic)
})

for (i in c(1:5)) {
  print(ttest_x[[i]]$p.value)
}
```

### Coarsened Exact Matching
```{r, error=TRUE, message=FALSE}
ttest_c <- lapply(ecls_cov, function(v) {
    t.test(dta_c[, v] ~ dta_c$catholic)
})

for (i in c(1:5)) {
  print(ttest_c[[i]]$p.value)
}
```

### Neigherest neighbor propensity score matching
```{r, error=TRUE, message=FALSE}
ttest_m <- lapply(ecls_cov, function(v) {
    t.test(dta_m[, v] ~ dta_m$catholic)
})

for (i in c(1:5)) {
  print(ttest_m[[i]]$p.value)
}
```

# 6. Estimating treatment effects

OLS
```{r}
with(dta_m, t.test(test_std ~ catholic))

lm_treat1 <- lm(test_std ~ catholic, data = dta_m)
summary(lm_treat1)

lm_treat2 <- lm(test_std ~ catholic + race_white + p5hmage +
                  I(w3income / 10^3) + p5numpla + w3momed_hsb, data = dta_m)
summary(lm_treat2)
```
